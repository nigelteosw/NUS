# Informed Search

A search strategy is defined by picking the **order of node expansion.**
Informed search allows us to throw away the extra stuff.
- which nodes are "better" or closer to the destination

## Types of informed searches

### Best-first Search
Greedy best-first search expands the node that **appears** closest to the goal.

#### Properties:
- Complete
	- No can get stuck in infinite loops
- Time
	- O(b<sup>m</sup>) but a good heuristic can give a better improvement
- Space
	- O(b<sup>m</sup>) keep all nodes in memory
- Optimal
	- No. m: maximum depth of search tree


### A star Search
A* algorithm is a well-known and widely used algorithm for solving pathfinding and graph traversal problems, because it is provably optimal, meaning that it is guaranteed to find the shortest path to the goal state, given that the heuristic function used is admissible and consistent. However, there are situations where using A* might not be the best option.

#### Idea
Avoid expanding paths that are already expensive

#### Properties:
- Complete
	- Yes
- Time
	- Exponential
- Space
	- Keep all nodes in memory
- Optimal
	- Yes


### Memory-bounded Heuristic Search
#### Problem
A* requires exponential amount of memory

#### Solution
Drop the node(s) with the worst f-value aka pruning
- this may still drop a node that contains the correct end state (loss of completeness)


### Hill-climbing Search
Picking the best out of the next expanded steps
Do not care about path cost, but use heuristics to pick the best 

#### Problem
Can get stuck in local maxima
- nearby states are much bigger yet current state is not destination

#### Solution
Introduce randomness to the algorithm to break out of local maxima

**n-Queens problem**
Allowing some "bad" moves but **gradually decrease** their frequency 


### Beam Search
Performing k hill-climbing searches in parallel

#### Variants:
- Local beam search : k threads share information 
- Stochastic beam search : k independent threads


### Genetic Algorithm
Generating new states then culls the state, then keep repeating
- A successor state is generated by combining two parent states
- Start with k randomly generated states (population)
- A state is represented as a string over a finite alphabet (often a string of 0s and 1s)
- Evaluation function (fitness function). Higher values for better states
- Produce the next generation of states by selection, crossover, and mutation



## Admissible heuristics 
A heuristic h(n) is **admissible** if for every node n, h(n) ≤ h*(n), where h*(n) is the true cost to reach the goal state from n.

- An admissible heuristic **never over-estimates** the cost to reach the goal, i.e., it is a **conservative estimate**

## Consistent heuristics
A heuristic is **consistent** if for every node n, every successor n' of n generated by any action a
h(n) ≤ c(n, a, n') + h(n') (triangle inequality)

**Theorem:** If h(n) is consistent, A* using GRAPH-SEARCH is optimal


## Dominance
- If h2(n) ≥ h1(n) for all n (both admissible) 
	- then h2 dominates h1 
	- h2 is better for search

A problem with fewer restrictions on the actions is called a **relaxed problem**
The cost of an optimal solution to a relaxed problem is an admissible heuristic for the original problem

#### H1
The function "h1" is an admissible heuristic, which means that it never overestimates the cost of reaching the goal state. This means that if h1(n) is the estimated cost of reaching the goal state from a given state n, then the actual cost of reaching the goal state from n will always be less than or equal to h1(n).

#### H2 
The function "h2" is also an admissible heuristic, but it is sometimes used as a "consistency check" to ensure that h1 is also consistent. A consistent heuristic is one in which the estimated cost of reaching the goal state from a given state plus the estimated cost of reaching that state from its predecessor is never less than the estimated cost of reaching the goal state from the predecessor.

Examples of “relaxed” problems 
1. A tile can move from square A to square B if A is adjacent to B (H1)
2. A tile can move from square A to square B if B is blank (H2)


# Adversial Search
Unpredictable” opponent
Time limits
- specifying a move for every possible opponent reply takes too long

**Key assumption is that opponent also reacts optimally (rationally)**

#### Formal Description:
- Initial state
- Successor function
- Terminal Test
- Utility Function

## Minimax
- Perfect play for deterministic games
- Idea: choose move to position with highest **minimax value** = best achievable payoff agianst best play

#### Properties:
- Complete
	- Yes
- Time
	- O(b<sup>m</sup>) 
- Space
	- O(bm) depth-first exploration
- Optimal
	- Yes against an optimal opponent

If we keep track of the maximum and minimum values seen thus far, we can ignore some paths that we would never choose

### The α-β algorithm
The basic idea behind alpha-beta pruning is to maintain two values, alpha and beta, that represent the best score that the maximizing player (i.e., the player whose turn it is) and the minimizing player (i.e., the opponent) can guarantee, respectively. These values are passed down the tree as the algorithm recursively evaluates different moves.

When the algorithm reaches a node, it first compares the current alpha and beta values with the score of the node. If the score is greater than or equal to beta, then the maximizing player will not choose this move, and the algorithm can prune the entire subtree rooted at that node, since it will not affect the final decision. Similarly, if the score is less than or equal to alpha, then the minimizing player will not choose this move, and the algorithm can prune the entire subtree rooted at that node.

Alpha-beta pruning can greatly improve the efficiency of the minimax algorithm, by avoiding searching certain branches of the game tree that will not affect the final decision. It allows the algorithm to search deeper in the tree, resulting in a better move. Theoretically, the algorithm can prune away all but a constant fraction of the total number of nodes, making it significantly faster than an algorithm that doesn't use any pruning.


## Evaluation Functions
For chess, typically linear weighted sum of features:
- Eval(s) = w1 f1(s) + w2 f2(s) + … + wn fn(s)
- Caveat: assumes independence of the features
	- Bishops in chess better at endgame 
	- Unmoved king and rook needed for castling


