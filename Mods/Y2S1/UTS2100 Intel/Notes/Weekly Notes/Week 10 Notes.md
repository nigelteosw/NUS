# Week 10 Notes
**[https://bit.ly/tembu-intel22wk10t](https://bit.ly/tembu-intel22wk10t)**

## Main arguments of current machines being intelligent
- Only as creative as the creator
- Inability to set goals by themselves
- Cannot make sense of the world
- Unable to be held accountable as they are not part of the world
- Not self regulating as of now, cannot hold themselves accountable

### Intelligent because
- intelligent in a different way. 
- Can create, test and evaluate (other code).  
- Can act autonomously within a space.  
- Learn within a space.  
- Are programmed as humans are.  
- Can draw on past experiences.  
- Exhibit ‘blind spots’ in being able to learn like humans do.

### Not intelligent because
- Don’t possess general intelligence (x3).  
- Lack an overall ‘executive’.  
- Are dependent on humans for intelligence (x3).  
- Can’t do tasks not trained for (x2).  
- Don’t set their own goals.  
- Can’t perform a variety of tasks.  
- Can’t really learn.  
- Can’t change viewpoint.  
- Can’t make sense of the world.  
- Don’t recognize, just map.  
- Can’t perform natural language processing.  
- Lack creativity.  
- Have intelligence projected upon them.  
- Unable to make decisions based on emotions.


This week's differences
- Self regulating (overreliance on humans for now)
- Definition of intelligence
	- consensus backed by science


## Judgement
Showing us that humans can exhibit judgement by showing where the machines cannot
Humans are emotional creatures that don't act rationally

Idea of reckoning, machines are not able to relate a world view to the decisions they make

## Neil Nie Ted Talk
- Slippage
	- Idea of intelligence being promoted that is not as intelligence
	- Word with multiple meanings

- **Learning Algorithms**
	- Powers computers to learn and be intelligent
	- Image processing
		- computers see things made of pixels
		- Separate into different parts/regions
		- Input to Meaning (algorithm)
		- Meaning to Learning and improvement (neural networks)
		  
		- computer vision and human vision
			- humans and computers don't process vision the same way we do
			- we link the boxes together to mean something
			- linking pixels vs seeing as a whole
			- idea or impression of an image
		- Memory
			- We don't store memory like how machines do
			- Stores it as bits and code
				- hard data
			- We store it as an idea/image
		- Learn
			- Identifying the object
			- Generates a model
				- Less internal representation
		- Meaning 
			- Meaning is different for humans as it is for machines
			- Mapping between stimulus and representation
			
	- Neural networks

**Words that have slippage**
- neurological
- perceptual
	- machine seems to perceive like a human
- ontological
	- relation vs understanding
	- working in the same world
	- doesn't really know about the real world
- epistemological

Elementary logic
Computational thinking
- Things that are seen as desirable

More complex mappings between what is observed and what they label it to be
A machine does not need definitions

### Judgment vs reckoning
- Merely just getting statistics out, hence only reckoning
- If it was making judgement then the machine would make a decision for the person
	- Lack of richness of experience
	- Requires ethical reasoning
	- Reducing ethical decisions to algorithms

Acknowledging limits of the technology is important
- Never working in isolation, but with human judgement
- This happens in a situated context


![[Pasted image 20221018153828.png | 500]]
